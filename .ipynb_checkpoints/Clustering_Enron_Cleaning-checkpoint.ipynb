{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 6)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/nadanadia/Documents/GitHub/Learning/emails.csv', sep=\";\", nrows=10000)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>cc</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>msagel@home.com</td>\n",
       "      <td>jarnold@enron.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Status</td>\n",
       "      <td>Thu, 16 Nov 2000 09:30:00 -0800 (PST)</td>\n",
       "      <td>John:\\n?\\nI'm not really sure what happened be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>slafontaine@globalp.com</td>\n",
       "      <td>john.arnold@enron.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>re:summer inverses</td>\n",
       "      <td>Fri, 8 Dec 2000 05:05:00 -0800 (PST)</td>\n",
       "      <td>i suck-hope youve made more money in natgas la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>iceoperations@intcx.com</td>\n",
       "      <td>icehelpdesk@intcx.com, internalmarketing@intcx...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The WTI Bullet swap contracts</td>\n",
       "      <td>Tue, 15 May 2001 09:43:00 -0700 (PDT)</td>\n",
       "      <td>Hi,\\n\\n\\n  Following the e-mail you have rece...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jeff.youngflesh@enron.com</td>\n",
       "      <td>anthony.gilmore@enron.com, colleen.koenig@enro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Invitation: EBS/GSS Meeting w/Bristol Babcock ...</td>\n",
       "      <td>Mon, 27 Nov 2000 01:49:00 -0800 (PST)</td>\n",
       "      <td>Conference Room TBD.  \\n\\nThis meeting will be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>caroline.abramo@enron.com</td>\n",
       "      <td>mike.grigsby@enron.com</td>\n",
       "      <td>john.arnold@enron.com</td>\n",
       "      <td>Harvard Mgmt</td>\n",
       "      <td>Tue, 12 Dec 2000 09:33:00 -0800 (PST)</td>\n",
       "      <td>Mike- I have their trader coming into the offi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>klarnold@flash.net</td>\n",
       "      <td>john.arnold@enron.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fwd: NYTimes.com Article: Suspended Rabbi Quit...</td>\n",
       "      <td>Mon, 11 Dec 2000 23:52:00 -0800 (PST)</td>\n",
       "      <td>&gt;Sender: articles-email@ms1.lga2.nytimes.com\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>outlook.team@enron.com</td>\n",
       "      <td>aimee.shek@enron.com, albino.lopez@enron.com, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4-URGENT - OWA Please print this now.</td>\n",
       "      <td>Fri, 11 May 2001 08:56:00 -0700 (PDT)</td>\n",
       "      <td>Current Notes User:\\n\\nREASONS FOR USING OUTLO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>jennifer.fraser@enron.com</td>\n",
       "      <td>alex.mcleish@enron.com, sarah.mulholland@enron...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fuel Switching</td>\n",
       "      <td>Sun, 19 Nov 2000 09:34:00 -0800 (PST)</td>\n",
       "      <td>The attached report contains an analysis of fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>caroline.abramo@enron.com</td>\n",
       "      <td>john.arnold@enron.com, mike.maggi@enron.com</td>\n",
       "      <td>per.sekse@enron.com, russell.dyk@enron.com, ro...</td>\n",
       "      <td>Guggenheim Event</td>\n",
       "      <td>Tue, 15 May 2001 03:28:00 -0700 (PDT)</td>\n",
       "      <td>John/Mike- Hi.. this is the list of people att...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>soblander@carrfut.com</td>\n",
       "      <td>soblander@carrfut.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>daily charts and matrices as hot links 5/15</td>\n",
       "      <td>Mon, 14 May 2001 23:59:00 -0700 (PDT)</td>\n",
       "      <td>The information contained herein is based on s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        from  \\\n",
       "0            msagel@home.com   \n",
       "1    slafontaine@globalp.com   \n",
       "2    iceoperations@intcx.com   \n",
       "3  jeff.youngflesh@enron.com   \n",
       "4  caroline.abramo@enron.com   \n",
       "5         klarnold@flash.net   \n",
       "6     outlook.team@enron.com   \n",
       "7  jennifer.fraser@enron.com   \n",
       "8  caroline.abramo@enron.com   \n",
       "9      soblander@carrfut.com   \n",
       "\n",
       "                                                  to  \\\n",
       "0                                  jarnold@enron.com   \n",
       "1                              john.arnold@enron.com   \n",
       "2  icehelpdesk@intcx.com, internalmarketing@intcx...   \n",
       "3  anthony.gilmore@enron.com, colleen.koenig@enro...   \n",
       "4                             mike.grigsby@enron.com   \n",
       "5                              john.arnold@enron.com   \n",
       "6  aimee.shek@enron.com, albino.lopez@enron.com, ...   \n",
       "7  alex.mcleish@enron.com, sarah.mulholland@enron...   \n",
       "8        john.arnold@enron.com, mike.maggi@enron.com   \n",
       "9                              soblander@carrfut.com   \n",
       "\n",
       "                                                  cc  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                              john.arnold@enron.com   \n",
       "5                                                NaN   \n",
       "6                                                NaN   \n",
       "7                                                NaN   \n",
       "8  per.sekse@enron.com, russell.dyk@enron.com, ro...   \n",
       "9                                                NaN   \n",
       "\n",
       "                                             subject  \\\n",
       "0                                             Status   \n",
       "1                                 re:summer inverses   \n",
       "2                      The WTI Bullet swap contracts   \n",
       "3  Invitation: EBS/GSS Meeting w/Bristol Babcock ...   \n",
       "4                                       Harvard Mgmt   \n",
       "5  Fwd: NYTimes.com Article: Suspended Rabbi Quit...   \n",
       "6              4-URGENT - OWA Please print this now.   \n",
       "7                                     Fuel Switching   \n",
       "8                                   Guggenheim Event   \n",
       "9        daily charts and matrices as hot links 5/15   \n",
       "\n",
       "                                    date  \\\n",
       "0  Thu, 16 Nov 2000 09:30:00 -0800 (PST)   \n",
       "1   Fri, 8 Dec 2000 05:05:00 -0800 (PST)   \n",
       "2  Tue, 15 May 2001 09:43:00 -0700 (PDT)   \n",
       "3  Mon, 27 Nov 2000 01:49:00 -0800 (PST)   \n",
       "4  Tue, 12 Dec 2000 09:33:00 -0800 (PST)   \n",
       "5  Mon, 11 Dec 2000 23:52:00 -0800 (PST)   \n",
       "6  Fri, 11 May 2001 08:56:00 -0700 (PDT)   \n",
       "7  Sun, 19 Nov 2000 09:34:00 -0800 (PST)   \n",
       "8  Tue, 15 May 2001 03:28:00 -0700 (PDT)   \n",
       "9  Mon, 14 May 2001 23:59:00 -0700 (PDT)   \n",
       "\n",
       "                                                body  \n",
       "0  John:\\n?\\nI'm not really sure what happened be...  \n",
       "1  i suck-hope youve made more money in natgas la...  \n",
       "2   Hi,\\n\\n\\n  Following the e-mail you have rece...  \n",
       "3  Conference Room TBD.  \\n\\nThis meeting will be...  \n",
       "4  Mike- I have their trader coming into the offi...  \n",
       "5  >Sender: articles-email@ms1.lga2.nytimes.com\\n...  \n",
       "6  Current Notes User:\\n\\nREASONS FOR USING OUTLO...  \n",
       "7  The attached report contains an analysis of fu...  \n",
       "8  John/Mike- Hi.. this is the list of people att...  \n",
       "9  The information contained herein is based on s...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the Null in each columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "from          0\n",
       "to          409\n",
       "cc         8777\n",
       "subject    1896\n",
       "date          0\n",
       "body          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "from        0.00\n",
       "to          4.09\n",
       "cc         87.77\n",
       "subject    18.96\n",
       "date        0.00\n",
       "body        0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum() * 100 / len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4047"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check only the email's body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       John:\\n?\\nI'm not really sure what happened be...\n",
       "1       i suck-hope youve made more money in natgas la...\n",
       "2        Hi,\\n\\n\\n  Following the e-mail you have rece...\n",
       "3       Conference Room TBD.  \\n\\nThis meeting will be...\n",
       "4       Mike- I have their trader coming into the offi...\n",
       "                              ...                        \n",
       "9995    Carol St. Clair\\nEB 3892\\n713-853-3989 (Phone)...\n",
       "9996    Morris:\\nThanks for your input.  Harry Collins...\n",
       "9997    John:\\nI was reviewing an amendment that Susan...\n",
       "9998    Carol St. Clair\\nEB 3892\\n713-853-3989 (Phone)...\n",
       "9999    Shari:\\nThe confirms desk has asked us to thin...\n",
       "Name: body, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body = df['body']\n",
    "body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import spacy\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = body.values.tolist()\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['conference', 'room', 'tbd', 'this', 'meeting', 'will', 'be', 'to', 'discuss', 'opportunity', 'for', 'ebs', 'to', 'provide', 'the', 'network', 'for', 'bbi', 'well', 'site', 'reporting', 'systems', 'to', 'send', 'their', 'data', 'across', 'maybe', 'vbn', 'ipnetconnect', 'application']\n"
     ]
    }
   ],
   "source": [
    "def words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(simple_preprocess(str(sentence), deacc=True)) #deacc =True removes punctuations\n",
    "\n",
    "data_words = list(words(data))\n",
    "print(data_words[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.phrases import Phrases, Phraser\n",
    "\n",
    "bigram = Phrases(data_words, min_count=5, threshold=100)\n",
    "trigram = Phrases(bigram[data_words], threshold=100)\n",
    "\n",
    "bigram_mod = Phraser(bigram)\n",
    "trigram_mod = Phraser(trigram)\n",
    "\n",
    "print(trigram_mod[bigram_mod[data_words[200]]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip3 install -U pip setuptools wheel\n",
    "#pip3 install -U spacy\n",
    "#python3 -m spacy download en_core_web_sm\n",
    "\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nltk.download('stopwords')\n",
    "\n",
    "my_stopwords = stopwords.words('english')\n",
    "my_stopwords.extend(['from', 'subject', 're', 'edu', 'use', 'ect', 'hou', 'com', 'recipient', 'sent', 'enron', 'cc', 'subject',\n",
    "                                         'forwarded', 'corp', 'said', 'attached', 'ect',\n",
    "                                         'recipient', 'email', 'original', 'doc', 'pm', 'mail', 'message', 'new',\n",
    "                                         'enronxgate', 'na', 'year'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#my_stopwords = text.ENGLISH_STOP_WORDS.union(['ect', 'hou', 'com', 'recipient', 'sent', 'enron', 'cc', 'subject', 'forwarded', 'corp', 'said', 'attached', 'ect', 'recipient', 'email', 'original', 'doc', 'pm', 'mail', 'message', 'new', 'enronxgate', 'na', 'year'])\n",
    "\n",
    "def remove_stopwords(texts):\n",
    "    return[[word for word in simple_preprocess(str(doc)) if word not in my_stopwords] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return[bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigram(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent))\n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags = ['NOUN', 'ADJ', 'VERB', 'ADV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "texts = data_lemmatized\n",
    "corpus =[id2word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim \n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=, num_topics=20, random_state=1, update_every=1, chunksize=100, passes=10, alpha='auto', per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lda_model.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim_models as gensimvis\n",
    "\n",
    "\n",
    "pyLDAvis.enable_notebook(sort=True)\n",
    "vis = gensimvis.prepare(lda_model, corpus, id2word)\n",
    "pyLDAvis.display(vis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "cols = [color for name, color in mcolors.TABLEAU_COLORS.items()]  # more colors: 'mcolors.XKCD_COLORS'\n",
    "\n",
    "cloud = WordCloud(stopwords=my_stopwords,\n",
    "                  background_color='white',\n",
    "                  width=2500,\n",
    "                  height=1800,\n",
    "                  max_words=10,\n",
    "                  colormap='tab10',\n",
    "                  color_func=lambda *args, **kwargs: cols[i],\n",
    "                  prefer_horizontal=1.0)\n",
    "\n",
    "topics = lda_model.show_topics(formatted=False, )\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10,10), sharex=True, sharey=True)\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    fig.add_subplot(ax)\n",
    "    topic_words = dict(topics[i][1])\n",
    "    cloud.generate_from_frequencies(topic_words, max_font_size=300)\n",
    "    plt.gca().imshow(cloud)\n",
    "    plt.gca().set_title('Topic ' + str(i), fontdict=dict(size=16))\n",
    "    plt.gca().axis('off')\n",
    "\n",
    "\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "plt.axis('off')\n",
    "plt.margins(x=0, y=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
