{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>cc</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kpeterso@epelectric.com</td>\n",
       "      <td>bill.williams@enron.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Re: Models</td>\n",
       "      <td>Wed, 23 May 2001 13:21:33 -0700 (PDT)</td>\n",
       "      <td>\\nHi Bill,\\n\\nI know you have been out and I w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kpeterso@epelectric.com</td>\n",
       "      <td>bill.williams.iii@enron.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Re: Model for 04-19</td>\n",
       "      <td>Fri, 20 Apr 2001 19:57:00 -0700 (PDT)</td>\n",
       "      <td>\\nHi Bill,\\n\\nOn yesterday's...HE16 from SRP s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kpeterso@epelectric.com</td>\n",
       "      <td>bill.williams@enron.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RE: Model for 04-25</td>\n",
       "      <td>Wed, 2 May 2001 16:05:19 -0700 (PDT)</td>\n",
       "      <td>\\nSorry Bill,\\n\\nBut one more time...the ancil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kpeterso@epelectric.com</td>\n",
       "      <td>bill.williams.iii@enron.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Re: Model for 04-17 and 04-18</td>\n",
       "      <td>Thu, 19 Apr 2001 17:39:00 -0700 (PDT)</td>\n",
       "      <td>\\nHi Bill,\\n\\nJust a couple of things on these...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kpeterso@epelectric.com</td>\n",
       "      <td>bill.williams@enron.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RE: Model for 04-25</td>\n",
       "      <td>Wed, 2 May 2001 15:33:07 -0700 (PDT)</td>\n",
       "      <td>\\nThanks for your help Bill.\\n\\nOne little thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>george.ellis@americas.bnpparibas.com</td>\n",
       "      <td>george_ellis@americas.bnpparibas.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BNP PARIBAS Commodity Futures AGA Survey.........</td>\n",
       "      <td>Wed, 23 Jan 2002 09:28:18 -0800 (PST)</td>\n",
       "      <td>\\n\\nHere are this week's survey results.\\n\\nAV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>tmartin@nymex.com</td>\n",
       "      <td>martin@enron.com, tmartin@nymex.com</td>\n",
       "      <td>gonzalez@enron.com, mgonzalez@nymex.com</td>\n",
       "      <td>Nymex statistics for week ending 10/19/01</td>\n",
       "      <td>Wed, 24 Oct 2001 06:53:58 -0700 (PDT)</td>\n",
       "      <td>- NYMEXWEEKLY.xls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>michelle.nelson@enron.com</td>\n",
       "      <td>mike.maggi@enron.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tue, 20 Nov 2001 10:41:23 -0800 (PST)</td>\n",
       "      <td>thanks for calling sir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>michelle.nelson@enron.com</td>\n",
       "      <td>mike.maggi@enron.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RE:</td>\n",
       "      <td>Wed, 21 Nov 2001 10:02:14 -0800 (PST)</td>\n",
       "      <td>are you sure about that?  i am bored.\\n\\n ----...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>bnpparibascommodityfutureslimited@bnpparibas.com</td>\n",
       "      <td>bnpparibascommodityfutureslimited@bnpparibas.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FUTURES SPREAD INDICATIONS</td>\n",
       "      <td>Tue, 5 Feb 2002 15:41:01 -0800 (PST)</td>\n",
       "      <td>(See attached file: closenc.pdf)\\n\\nThis messa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  from  \\\n",
       "0                              kpeterso@epelectric.com   \n",
       "1                              kpeterso@epelectric.com   \n",
       "2                              kpeterso@epelectric.com   \n",
       "3                              kpeterso@epelectric.com   \n",
       "4                              kpeterso@epelectric.com   \n",
       "...                                                ...   \n",
       "9995              george.ellis@americas.bnpparibas.com   \n",
       "9996                                 tmartin@nymex.com   \n",
       "9997                         michelle.nelson@enron.com   \n",
       "9998                         michelle.nelson@enron.com   \n",
       "9999  bnpparibascommodityfutureslimited@bnpparibas.com   \n",
       "\n",
       "                                                    to  \\\n",
       "0                              bill.williams@enron.com   \n",
       "1                          bill.williams.iii@enron.com   \n",
       "2                              bill.williams@enron.com   \n",
       "3                          bill.williams.iii@enron.com   \n",
       "4                              bill.williams@enron.com   \n",
       "...                                                ...   \n",
       "9995              george_ellis@americas.bnpparibas.com   \n",
       "9996               martin@enron.com, tmartin@nymex.com   \n",
       "9997                              mike.maggi@enron.com   \n",
       "9998                              mike.maggi@enron.com   \n",
       "9999  bnpparibascommodityfutureslimited@bnpparibas.com   \n",
       "\n",
       "                                           cc  \\\n",
       "0                                         NaN   \n",
       "1                                         NaN   \n",
       "2                                         NaN   \n",
       "3                                         NaN   \n",
       "4                                         NaN   \n",
       "...                                       ...   \n",
       "9995                                      NaN   \n",
       "9996  gonzalez@enron.com, mgonzalez@nymex.com   \n",
       "9997                                      NaN   \n",
       "9998                                      NaN   \n",
       "9999                                      NaN   \n",
       "\n",
       "                                                subject  \\\n",
       "0                                            Re: Models   \n",
       "1                                   Re: Model for 04-19   \n",
       "2                                   RE: Model for 04-25   \n",
       "3                         Re: Model for 04-17 and 04-18   \n",
       "4                                   RE: Model for 04-25   \n",
       "...                                                 ...   \n",
       "9995  BNP PARIBAS Commodity Futures AGA Survey.........   \n",
       "9996          Nymex statistics for week ending 10/19/01   \n",
       "9997                                                NaN   \n",
       "9998                                                RE:   \n",
       "9999                         FUTURES SPREAD INDICATIONS   \n",
       "\n",
       "                                       date  \\\n",
       "0     Wed, 23 May 2001 13:21:33 -0700 (PDT)   \n",
       "1     Fri, 20 Apr 2001 19:57:00 -0700 (PDT)   \n",
       "2      Wed, 2 May 2001 16:05:19 -0700 (PDT)   \n",
       "3     Thu, 19 Apr 2001 17:39:00 -0700 (PDT)   \n",
       "4      Wed, 2 May 2001 15:33:07 -0700 (PDT)   \n",
       "...                                     ...   \n",
       "9995  Wed, 23 Jan 2002 09:28:18 -0800 (PST)   \n",
       "9996  Wed, 24 Oct 2001 06:53:58 -0700 (PDT)   \n",
       "9997  Tue, 20 Nov 2001 10:41:23 -0800 (PST)   \n",
       "9998  Wed, 21 Nov 2001 10:02:14 -0800 (PST)   \n",
       "9999   Tue, 5 Feb 2002 15:41:01 -0800 (PST)   \n",
       "\n",
       "                                                   body  \n",
       "0     \\nHi Bill,\\n\\nI know you have been out and I w...  \n",
       "1     \\nHi Bill,\\n\\nOn yesterday's...HE16 from SRP s...  \n",
       "2     \\nSorry Bill,\\n\\nBut one more time...the ancil...  \n",
       "3     \\nHi Bill,\\n\\nJust a couple of things on these...  \n",
       "4     \\nThanks for your help Bill.\\n\\nOne little thi...  \n",
       "...                                                 ...  \n",
       "9995  \\n\\nHere are this week's survey results.\\n\\nAV...  \n",
       "9996                                 - NYMEXWEEKLY.xls   \n",
       "9997                             thanks for calling sir  \n",
       "9998  are you sure about that?  i am bored.\\n\\n ----...  \n",
       "9999  (See attached file: closenc.pdf)\\n\\nThis messa...  \n",
       "\n",
       "[10000 rows x 6 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/home/anjali/Becode_projects/Clustering_Enron/emails.csv\",sep =\";\", nrows = 10000)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "from        0.00\n",
       "to          4.33\n",
       "cc         70.60\n",
       "subject     2.59\n",
       "date        0.00\n",
       "body        0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum() * 100 / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2264"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       \\nHi Bill,\\n\\nI know you have been out and I w...\n",
       "1       \\nHi Bill,\\n\\nOn yesterday's...HE16 from SRP s...\n",
       "2       \\nSorry Bill,\\n\\nBut one more time...the ancil...\n",
       "3       \\nHi Bill,\\n\\nJust a couple of things on these...\n",
       "4       \\nThanks for your help Bill.\\n\\nOne little thi...\n",
       "                              ...                        \n",
       "9995    \\n\\nHere are this week's survey results.\\n\\nAV...\n",
       "9996                                   - NYMEXWEEKLY.xls \n",
       "9997                               thanks for calling sir\n",
       "9998    are you sure about that?  i am bored.\\n\\n ----...\n",
       "9999    (See attached file: closenc.pdf)\\n\\nThis messa...\n",
       "Name: body, Length: 7736, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_body = df[\"body\"]\n",
    "email_body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all libraries \n",
    "import gensim\n",
    "import gensim.corpora as corpora \n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "import nlp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7736"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert email body  to list : create list of messages \n",
    "data = email_body.values.tolist()\n",
    "len(data)                       # check length of list is sames no. of rows in dataset : correct "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Breakdown each sentence into a list of words : tokenize \n",
    "def sent_to_words(sentences): \n",
    "    for sentence in sentences: \n",
    "        yield(simple_preprocess(str(sentence), deacc = True))  # deacc = True removes punctuations\n",
    "\n",
    "data_words = list(sent_to_words(data))\n",
    "\n",
    "# print(data_words[3])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.phrases import Phrases, Phraser \n",
    "\n",
    "# BUild the bigram and trigrams models \n",
    "bigram = Phrases(data_words, min_count = 5, threshold = 100)\n",
    "\n",
    "trigram = Phrases(bigram[data_words], threshold = 100)\n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = Phraser(bigram)\n",
    "trigram_mod = Phraser(trigram)\n",
    "\n",
    "# print(trigram_mod[bigram_mod[data_words[200]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization \n",
    "import spacy \n",
    "import nlp \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/anjali/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "# prep NLTK Stop words\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# remove stop_words, make bigrams and lemmatize\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent))\n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data_lemmatized[200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary and corpus both are needed for (LDA) topic modeling\n",
    "\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=20,\n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "import matplotlib.pyplot as plt \n",
    "import nltk"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
